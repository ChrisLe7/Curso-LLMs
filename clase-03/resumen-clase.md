# Resumen de la Clase 3 ‚Äì Herramientas y Plataformas Basadas en LLMs

Esta tercera sesi√≥n del curso **‚ÄúLLMs en Programaci√≥n: De la Generaci√≥n de C√≥digo a la Soluci√≥n de Problemas‚Äù** se centra en el ecosistema de herramientas basadas en LLMs, desde asistentes en la nube como GitHub Copilot o ChatGPT hasta la instalaci√≥n de modelos locales con Ollama y alternativas como LM Studio o Text Generation WebUI.

## 1. Introducci√≥n

* Los LLMs se integran en entornos de programaci√≥n mediante distintas plataformas.
* El objetivo de la sesi√≥n es **comparar herramientas**, entender sus ventajas y limitaciones, y practicar con ellas en tareas de desarrollo.

## 2. GitHub Copilot

* **Qu√© es**: asistente de autocompletado y generaci√≥n de c√≥digo integrado en editores como VSCode.
* **C√≥mo funciona**: sugiere c√≥digo en funci√≥n del contexto del archivo/proyecto.
* **Beneficios**:

  * Aceleraci√≥n en tareas repetitivas.
  * Mejores pr√°cticas y c√≥digo idiom√°tico.
  * Integraci√≥n fluida en el IDE.
* **Limitaciones**:

  * Contexto reducido al archivo actual.
  * Puede inducir errores sutiles.
  * No explica alternativas.
* **Casos de uso**:

  * Autocompletado inteligente de funciones.
  * Generaci√≥n de pruebas unitarias.
  * Conversi√≥n de c√≥digo entre lenguajes.
  * Documentaci√≥n autom√°tica.

## 3. ChatGPT y APIs de OpenAI

* **Qu√© es**: modelo conversacional para depurar, refactorizar y generar c√≥digo.
* **Ventajas**: interacci√≥n flexible, versatilidad en aplicaciones, acceso sencillo (web/API).
* **Limitaciones**: riesgo de alucinaciones, control limitado sobre el formato de salida, coste asociado a la suscripci√≥n.
* **Casos de uso**:

  * Explicaci√≥n de c√≥digo legado.
  * Refactorizaci√≥n y mejora de estilo.
  * Dise√±o de arquitecturas y patrones.
  * Generaci√≥n de scripts de configuraci√≥n (Dockerfile, GitHub Actions, etc.).

## 4. LLMs en local

* **Por qu√© ejecutarlos localmente**:

  * Mayor privacidad (los datos no salen de la m√°quina).
  * Uso offline y baja latencia.
  * Flexibilidad y coste cero (m√°s all√° del hardware).
* **Herramientas populares**:

  * **Ollama**: CLI para descargar y ejecutar modelos (LLaMA, Mistral, Gemma, CodeLlama‚Ä¶). Expone API HTTP local (`http://localhost:11434`).
  * **LM Studio**: GUI para descargar, probar y chatear con modelos en CPU/GPU.
  * **Text Generation WebUI**: entorno web para gestionar modelos, con instalaci√≥n m√°s avanzada.
  * **CodeGPT**: extensi√≥n para VSCode que conecta con APIs (OpenAI, HuggingFace, Anthropic) y con endpoints locales como Ollama.
* **Comparaci√≥n nube vs local**:

  * Nube: acceso inmediato a modelos grandes (GPT-4, Claude, Gemini), sin consumo de recursos locales.
  * Local: privacidad total, latencia m√≠nima, pero requiere hardware (CPU/GPU y espacio en disco).

## 5. Actividad pr√°ctica

* Comparaci√≥n entre Copilot y ChatGPT con el mismo prompt:

  > *‚ÄúGenera una funci√≥n en Python que lea un archivo CSV y calcule el promedio por columna num√©rica.‚Äù*
* Discusi√≥n posterior: diferencias de estilo, manejo de errores y casos en que conviene cada herramienta.

## 6. Conclusiones

* No hay una ‚Äúmejor herramienta universal‚Äù: la elecci√≥n depende del contexto (privacidad, recursos, tipo de tarea).
* Copilot destaca en autocompletado dentro del IDE.
* ChatGPT es m√°s flexible para explicaciones, dise√±o y generaci√≥n de scripts.
* Los LLMs locales (Ollama, LM Studio) son clave en proyectos sensibles o sin conexi√≥n.

---

## Material adicional

* **Manual de instalaci√≥n de Ollama** (incluido en la carpeta de recursos):

  * Explica instalaci√≥n en macOS, Windows, Linux y Docker.
  * Conceptos b√°sicos: tokens, contexto, cuantizaci√≥n, GGUF.
  * C√≥mo descargar, ejecutar y verificar modelos (`ollama pull`, `ollama run`).
  * Opciones para configurar almacenamiento, exponer API, ejecutar como servicio o contenedor.
  * Buenas pr√°cticas: persistencia de modelos, logs y seguridad al exponer la API.

* **Web oficial de Ollama**: [https://ollama.com](https://ollama.com)

* **LM Studio**: [https://lmstudio.ai](https://lmstudio.ai)

* **Extensi√≥n CodeGPT para VSCode**: [https://github.com/CodeGPT-org/CodeGPT-vscode](https://github.com/CodeGPT-org/CodeGPT-vscode)

---

üëâ **Pr√≥xima sesi√≥n (Clase 4):** *√âtica, riesgos y buenas pr√°cticas con LLMs en desarrollo de software*.
