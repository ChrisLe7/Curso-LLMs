# Resumen de la Clase 1 ‚Äì Fundamentos de los LLMs

Esta primera sesi√≥n del curso **‚ÄúLLMs en Programaci√≥n: De la Generaci√≥n de C√≥digo a la Soluci√≥n de Problemas‚Äù** introduce los conceptos b√°sicos de los **Grandes Modelos de Lenguaje (LLMs)**, su evoluci√≥n hist√≥rica, su arquitectura t√©cnica y su aplicaci√≥n pr√°ctica en el √°mbito de la programaci√≥n.

## 1. Introducci√≥n a la Inteligencia Artificial y los LLMs

* La IA tiene un doble objetivo: **tecnol√≥gico** (crear sistemas capaces de realizar tareas inteligentes) y **cient√≠fico** (comprender los fundamentos del comportamiento inteligente).
* La IA ya est√° presente en numerosos √°mbitos: generaci√≥n autom√°tica de texto, asistentes virtuales, diagn√≥stico m√©dico, detecci√≥n de fraudes, automatizaci√≥n industrial, etc.
* Los **LLMs** son modelos entrenados con grandes vol√∫menes de texto y c√≥digo, capaces de predecir la siguiente palabra en una secuencia y de capturar patrones complejos del lenguaje.

## 2. Evoluci√≥n hist√≥rica de los modelos de lenguaje

* **A√±os 90‚Äì2000:** modelos estad√≠sticos basados en n-gramas.
* **2000s:** redes neuronales recurrentes (RNN) y sus variantes LSTM y GRU, capaces de modelar dependencias a largo plazo.
* **2014‚Äì2017:** arquitecturas seq2seq y encoder-decoder para traducci√≥n y resumen autom√°tico.
* **2017:** aparici√≥n del **Transformer**, que marc√≥ un hito por su paralelizaci√≥n, atenci√≥n m√∫ltiple y escalabilidad.
* **2018‚Äì2025:** explosi√≥n de modelos como GPT-2, GPT-3, Codex, GPT-4, LLaMA, Gemini, DeepSeek, hasta los m√°s recientes optimizados para programaci√≥n y razonamiento.

## 3. Arquitectura y capacidades de los LLMs

* Componentes clave: **tokenizaci√≥n, embeddings, capas de atenci√≥n y redes apiladas**.
* La **auto-atenci√≥n** permite que cada token valore su relaci√≥n con el resto del contexto.
* La **escalabilidad** (m√°s par√°metros y datos) habilita capacidades emergentes como:

  * *Chain-of-thought* (razonamiento paso a paso).
  * *In-context learning* (aprender de ejemplos en el prompt).
  * Uso de herramientas externas (APIs, c√°lculos).
* El tama√±o del modelo determina un salto cualitativo en las tareas que puede realizar.

## 4. Aplicaciones en programaci√≥n

Los LLMs resultan especialmente √∫tiles porque el c√≥digo fuente es un lenguaje estructurado y abundante en repositorios p√∫blicos. Entre sus aplicaciones:

* Autocompletado inteligente (ej. GitHub Copilot, Amazon CodeWhisperer).
* Generaci√≥n de funciones a partir de descripciones en lenguaje natural.
* Explicaci√≥n, documentaci√≥n y refactorizaci√≥n de c√≥digo.
* Creaci√≥n de pruebas unitarias y casos de test.
* Depuraci√≥n asistida y sugerencias de buenas pr√°cticas.

Se revisaron casos espec√≠ficos para desarrolladores **backend**, **frontend**, **ingenier√≠a de datos** e **investigaci√≥n en ML**.

## 5. Limitaciones y riesgos

* Los modelos no ‚Äúentienden‚Äù el prop√≥sito: solo predicen tokens.
* Posibles **alucinaciones** (funciones o imports inexistentes).
* Dificultad con proyectos grandes y dependencias m√∫ltiples.
* Riesgos de seguridad (fugas de datos, licencias, vulnerabilidades).
* Dependencia excesiva que puede reducir la comprensi√≥n del programador.

## 6. Impacto, productividad y √©tica

* Estudios muestran mejoras de hasta **+55 % en velocidad de desarrollo** al usar asistentes de c√≥digo.
* Los LLMs **no sustituyen al programador**, sino que aumentan su productividad y reducen la barrera de entrada.
* Consideraciones √©ticas: sesgos en datos, privacidad, copyright y responsabilidad del uso del c√≥digo generado.
* Buenas pr√°cticas: verificar resultados, dise√±ar prompts claros, documentar el uso de las sugerencias.

## 7. Evaluaci√≥n de LLMs en programaci√≥n

* Benchmarks como **HumanEval**, **MBPP**, **Bugs-BUSTED** o **SWE-Bench** permiten medir precisi√≥n, generalizaci√≥n y capacidad de correcci√≥n.
* M√©tricas como **Pass\@k** ayudan a evaluar la probabilidad de obtener soluciones correctas en m√∫ltiples intentos.

## 8. Parte pr√°ctica

* Ejemplo de generaci√≥n de c√≥digo con ChatGPT/Copilot, mostrando la importancia de refinar los prompts.
* Ejercicio en clase: escribir un prompt para generar una funci√≥n que determine si un n√∫mero es primo, con manejo de errores y comentarios.

## 9. Conclusiones de la clase

* Los LLMs funcionan prediciendo tokens y capturando patrones gracias a la arquitectura Transformer.
* Su evoluci√≥n hist√≥rica y escalado han permitido la aparici√≥n de capacidades emergentes.
* En programaci√≥n, ofrecen grandes beneficios en productividad, pero tambi√©n presentan riesgos y limitaciones.
* El rol del programador cambia hacia un uso cr√≠tico y supervisado de estas herramientas.

---

üëâ **Pr√≥xima sesi√≥n (Clase 2):** *Prompt Engineering aplicado a programaci√≥n* ‚Äî fundamentos (zero-shot, one-shot, few-shot), dise√±o de prompts efectivos y casos pr√°cticos.

--- 


## Material adicional

Para complementar la clase, se recomienda revisar los siguientes recursos:

* **Blog visual sobre la evoluci√≥n de los LLMs**
  [https://goyalpramod.github.io/blogs/evolution\_of\_LLMs](https://goyalpramod.github.io/blogs/evolution_of_LLMs)

* **Survey de LLMs (arXiv, 2023)**
  [https://arxiv.org/html/2303.18223v16](https://arxiv.org/html/2303.18223v16)

* **Video canal DotCSV: ¬øPor qu√© estas REDES NEURONALES son tan POTENTES? ü§î | TRANSFORMERS Parte 2**
  [https://www.youtube.com/watch?v=xi94v\_jl26U](https://www.youtube.com/watch?v=xi94v_jl26U)

* **Art√≠culo acad√©mico de referencia**
  *History, development, and principles of large language models: an introductory survey* (AI & Ethics, 2025).
  Este trabajo ofrece una visi√≥n accesible sobre la evoluci√≥n, principios, aplicaciones, limitaciones y futuros desaf√≠os de los LLMs.